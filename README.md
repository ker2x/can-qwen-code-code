# Qwen-code-30b Testing Repository

## Note from the author

Hi there. I'm using Jetbrains AI Chat and Junie, with cloud model.
But i want to test local model as well. I picked this model because it's a MoE.
Let's see how it goes.

- The IDE (Pycharm) is a running on a Mac.
- The Ollama server is a small Beelink server running a Ryzen7 6800U that i bought for 380e on Amazon.
- I configured the BIOS to allocate 16GB as VRAM, out of the 32GGB of UMA Ram.
- As for now the context size is set to 20k token.
- It use all the VRAM + 3GB of GTT.

That's it. for now.

----

## Anything below is AI generated

This repository is dedicated to testing the capabilities of the Qwen-code-30b model as a local coding assistant within JetBrains IDEs using the JetBrains AI Chat feature.

## Purpose

The main goal of this repository is to experiment with and evaluate how well the Qwen-code-30b language model performs when used locally for various programming tasks within the JetBrains ecosystem. This includes testing code generation, debugging assistance, code completion, and other AI-powered coding features.

## Model Used

- **Model**: Qwen-code-30b (a large language model specialized for code understanding and generation)
- **Usage**: Local model deployment for offline coding assistance
- **Integration**: JetBrains AI Chat for IDE integration

## Features Being Tested

- Code generation from natural language descriptions
- refactoring suggestions
- Debugging assistance and error explanation
- Code documentation generation

## Contributing

Feel free to explore, test, and provide feedback on how well the model performs with different coding tasks.
